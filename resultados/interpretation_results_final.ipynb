{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **INTERPRETAÇÃO DOS RESULTADOS**\n",
    "Esta etapa do projeto consiste na avaliação e interpretação dos dados extraídos da análise do dataset, com o objetivo de compreender de forma aprofundada os resultados obtidos. Serão analisados **comportamento dos modelos e a eficácia de cada um deles, a análise exploratória dos dados, as técnicas de pré-processamento**, além de **discutir padrões, possíveis discrepâncias e resultados inesperados.** Também serão apresentadas **recomendações para aprimorar futuras análises**, tornando essa reflexão essencial para guiar os próximos passos do estudo.\n",
    "\n",
    "- No seguinte trecho de código, são inicializados e treinados quatro modelos de aprendizado supervisionado — Random Forest, Regressão Logística, K-Nearest Neighbors e Decision Tree — com o objetivo de comparar seus desempenhos na tarefa de classificação. Cada modelo é treinado com os dados disponíveis e avaliado com base em seu desempenho nos dados de teste, permitindo a escolha do algoritmo mais eficaz para o problema em questão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_predict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m dt_clf = DecisionTreeClassifier(random_state=\u001b[32m42\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Execute the 'train_predict' function for each classifier\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[43mtrain_predict\u001b[49m(rf_clf, X_train, y_train, X_test, y_test)\n\u001b[32m     15\u001b[39m train_predict(lr_clf, X_train, y_train, X_test, y_test)\n\u001b[32m     16\u001b[39m train_predict(knn_clf, X_train, y_train, X_test, y_test)\n",
      "\u001b[31mNameError\u001b[39m: name 'train_predict' is not defined"
     ]
    }
   ],
   "source": [
    "# Import the supervised learning models from sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize the models\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "lr_clf = LogisticRegression(max_iter=1000, random_state=42)\n",
    "knn_clf = KNeighborsClassifier()\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Execute the 'train_predict' function for each classifier\n",
    "train_predict(rf_clf, X_train, y_train, X_test, y_test)\n",
    "train_predict(lr_clf, X_train, y_train, X_test, y_test)\n",
    "train_predict(knn_clf, X_train, y_train, X_test, y_test)\n",
    "train_predict(dt_clf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. COMPORTAMENTO DOS MODELOS E COMPARACÃO DA EFICÁCIA ENTRE ELES**\n",
    "Esta seção do trabalho tem como objetivo analisar o comportamento dos modelos de aprendizado de máquina aplicados, avaliando seu desempenho por meio de métricas relevantes. Além disso, busca-se comparar a eficiência dos diferentes algoritmos para identificar aquele que apresenta o melhor equilíbrio entre precisão, robustez e capacidade de generalização.\n",
    "\n",
    "## **Métricas Utilizadas na Avaliação**\n",
    "As métricas aplicadas com **cross-validation** foram:\n",
    "\n",
    "* **Acurácia (accuracy):** Proporção de previsões corretas (positivas e negativas).\n",
    "\n",
    "* **Precisão (precision):** Proporção de verdadeiros positivos entre todos os positivos previstos.\n",
    "\n",
    "* **Recall:** Proporção de verdadeiros positivos entre todos os positivos reais.\n",
    "\n",
    "* **F1-Score (f1):** Média harmônica entre precisão e recall.\n",
    "\n",
    "* **Área sob a curva ROC (roc_auc):** Mede a capacidade do modelo em distinguir entre classes.\n",
    "\n",
    "### **Cross-validation**\n",
    "\n",
    "**O cross-validation (validação cruzada) serve para avaliar a performance dos modelos de forma mais robusta e confiável, evitando que o resultado dependa apenas de uma divisão específica dos dados em treino e teste.**\n",
    "\n",
    "**Ele permite:**\n",
    "\n",
    "- Estimativa mais realista da capacidade do modelo em generalizar dados novos;\n",
    "\n",
    "- Redução do risco de overfitting, já que o modelo é treinado e testado em diferentes subconjuntos dos dados;\n",
    "\n",
    "- Comparação justa entre diferentes modelos, usando as mesmas divisões para todas as avaliações;\n",
    "\n",
    "- Auxílio na escolha e ajuste de hiperparâmetros, garantindo que o modelo ajustado tenha bom desempenho consistente em várias amostras do conjunto.\n",
    "\n",
    "Ou seja, ajuda a garantir que a avaliação dos modelos seja confiável e que os resultados apresentados realmente reflitam a capacidade dos modelos de prever o desempenho dos estudantes em situações reais.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar e avaliar modelos usando validação cruzada\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    cv_results = cross_validate(\n",
    "        estimator=model,\n",
    "        X=X_scaled,\n",
    "        y=y_encoded,\n",
    "        cv=kf,\n",
    "        scoring=scoring,\n",
    "        return_train_score=True,\n",
    "        return_estimator=True\n",
    "    )\n",
    "    results[name] = cv_results\n",
    "\n",
    "# Exibir resultados\n",
    "print(\"\\nResultados da Validação Cruzada:\")\n",
    "print(f\"Acurácia Média: {np.mean(cv_results['test_accuracy']):.4f} (±{np.std(cv_results['test_accuracy']):.4f})\")\n",
    "print(f\"Precisão Média: {np.mean(cv_results['test_precision']):.4f} (±{np.std(cv_results['test_precision']):.4f})\")\n",
    "print(f\"Recall Médio: {np.mean(cv_results['test_recall']):.4f} (±{np.std(cv_results['test_recall']):.4f})\")\n",
    "print(f\"F1-Score Médio: {np.mean(cv_results['test_f1']):.4f} (±{np.std(cv_results['test_f1']):.4f})\")\n",
    "print(f\"ROC-AUC Médio: {np.mean(cv_results['test_roc_auc']):.4f} (±{np.std(cv_results['test_roc_auc']):.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os resultados apresentados correspondem à **média** das métricas de desempenho calculadas durante o processo de validação cruzada aplicado aos modelos. Essas métricas — incluindo acurácia, precisão, recall, F1-score e ROC-AUC — refletem a **performance média dos modelos** em diferentes divisões dos dados, fornecendo uma estimativa robusta e confiável da capacidade dos modelos em generalizar para novos conjuntos de dados. Dessa forma, a média dessas métricas permite uma avaliação mais consistente e representativa do comportamento dos modelos em variadas situações.s:\n",
    "\n",
    "- Acurácia Média (78,07%): O modelo classificou corretamente cerca de 78% dos casos, mostrando um nível sólido de precisão geral na previsão.\n",
    "\n",
    "- Precisão Média (83,23%): Quando o modelo prevê uma classe positiva, ele acerta em mais de 83% dos casos, indicando poucas classificações falsas positivas.\n",
    "\n",
    "- Recall Médio (70,61%): O modelo conseguiu identificar aproximadamente 71% dos casos positivos reais, evidenciando alguma dificuldade em capturar todos os exemplos da classe positiva.\n",
    "\n",
    "- F1-Score Médio (75,86%): O equilíbrio entre precisão e recall está bom, mas sugere que ainda há espaço para melhorar a sensibilidade sem perder a exatidão.\n",
    "\n",
    "- ROC-AUC Médio (77,96%): O modelo tem uma boa capacidade discriminativa entre as classes, o que reforça sua habilidade em diferenciar corretamente os casos positivos dos negativos.\n",
    "\n",
    "Além disso, os desvios padrão indicam que o desempenho é relativamente estável, com pequenas variações entre as diferentes divisões dos dados, especialmente para as métricas de acurácia, precisão e ROC-AUC. O recall apresenta maior variabilidade, o que pode sugerir que o modelo tem mais dificuldade em diferentes subconjuntos para capturar todos os exemplos positivos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **Avaliação e Comparação dos Modelos de Classificação**\n",
    "A tabela abaixo apresenta os resultados detalhados de desempenho utilizando o **cross-validation K-Fold (com k=5)** para avaliar e comparar os quatro modelos de classificação implementados.\n",
    "\n",
    "| Modelo | Acurácia | Precisão | Recall | F1-Score | ROC-AUC |\n",
    "|--------|----------|----------|--------|----------|--------|\n",
    "| Random Forest | 0.7737 (±0.0485) | 0.7560 (±0.0551) | 0.8161 (±0.0348) | 0.7839 (±0.0389) | 0.8397 (±0.0340) |\n",
    "| Logistic Regression | 0.7216 (±0.0282) | 0.7247 (±0.0502) | 0.7211 (±0.0383) | 0.7212 (±0.0284) | 0.7603 (±0.0321) |\n",
    "| KNN | 0.6061 (±0.0520) | 0.6050 (±0.0576) | 0.6115 (±0.0702) | 0.6069 (±0.0592) | 0.6486 (±0.0374) |\n",
    "| Decision Tree | 0.7807 (±0.0271) | 0.8323 (±0.0240) | 0.7061 (±0.1030) | 0.7586 (±0.0509) | 0.7796 (±0.0281) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.1 Análise Comparativa de Desempenho**\n",
    "\n",
    "Analisando detalhadamente o comportamento dos modelos implementados, observamos padrões distintos que revelam suas características fundamentais:\n",
    "\n",
    "### **Random Forest:**\n",
    "**Comportamento característico:**\n",
    "- Ensemble Learning: Combina múltiplas árvores de decisão (\"floresta\") para reduzir overfitting.\n",
    "\n",
    "- Alto Recall (0.8161): Excelente em identificar alunos em risco (poucos falsos negativos).\n",
    "\n",
    "- Bom Equilíbrio (F1-Score: 0.7839): Mantém razoável precisão enquanto maximiza recall.\n",
    "\n",
    "- Importância de Features: Prioriza variáveis como failures e absences (histórico escolar).\n",
    "\n",
    "**Pontos Fortes:**\n",
    "- **Recall** mais alto (0.8161): Para cada 100 alunos que realmente reprovariam, o modelo identifica corretamente 81.61, ou seja, a maioria dos alunos em risco.\n",
    "\n",
    "- **Precisão** (0.7560): Dos que ele classifica como \"reprovados\", 75.60% realmente reprovam. Ou seja, 24.4% são falsos positivos (alunos que passariam, mas foram sinalizados).\n",
    "\n",
    "- **F1-Score** (0.7839): Equilíbrio entre precisão e recall, superior aos outros modelos.\n",
    "\n",
    "**Pontos Fracos:**\n",
    "- Precisão menor que o modelo **Decision Tree**, ou seja, Pode classificar alguns alunos aprovados como \"em risco\" (precisão de 0.7560 vs. 0.8323 da Decision Tree), gerando intervenções desnecessárias.\n",
    "\n",
    "**Recomendação:**\n",
    "- Quando a prioridade é minimizar falsos negativos (ex.: não deixar passar alunos em risco).\n",
    "\n",
    "### **Logistic Regression:**\n",
    "**Comportamento característico:**\n",
    "- Modelo Linear: Assume uma relação linear entre features e o log-odds da classe.\n",
    "\n",
    "- Métricas Equilibradas (~0.72): Nenhum viés extremo para precisão ou recall.\n",
    "\n",
    "- Baixa Complexidade: Não captura relações não-lineares nos dados.\n",
    "\n",
    "**Pontos Fortes:**\n",
    "- Métricas equilibradas: Precisão e recall próximos (72%), sem viés extremo para falsos positivos ou negativos.\n",
    "\n",
    "- Estabilidade (baixo desvio padrão): Resultados consistentes em diferentes execuções.\n",
    "\n",
    "**Pontos Fracos:**\n",
    "- Desempenho inferior ao Random Forest e Decision Tree em acurácia, precisão, F1-Score e ROC-AUC.\n",
    "\n",
    "- Limitado para problemas complexos: Não captura relações não-lineares tão bem quanto os outros modelos.\n",
    "\n",
    "**Recomendação:**\n",
    "- Útil como baseline ou para interpretabilidade (ex.: entender quais variáveis mais impactam a reprovação). Não recomendado para implementação final.\n",
    "\n",
    "### **KNN:**\n",
    "**Comportamento característico:**\n",
    "- Baseado em Proximidade: Classifica alunos com base nos vizinhos mais próximos.\n",
    "\n",
    "- Desempenho Insatisfatório (~0,60): Próximo ao nível de uma classificação aleatória.\n",
    "\n",
    "- Alta Variabilidade: Desvios padrão grandes nas métricas.\n",
    "\n",
    "**Pontos Fortes:**\n",
    "- Nenhum em contexto educacional: Desempenho próximo ao acaso (0.5):\n",
    "\n",
    "**Pontos Fracos:**\n",
    "- Precisão e recall em torno de 0.60 indicam que o modelo erra quase 40% das previsões.\n",
    "\n",
    "- Alta variabilidade: Resultados inconsistentes entre execuções (desvios padrão altos).\n",
    "\n",
    "**Recomendacão:**\n",
    "- **Evitar**. Pode ser usado apenas para testes iniciais, mas não para decisões reais.\n",
    "\n",
    "### **Decision Tree:**\n",
    "**Comportamento característico:**\n",
    "- Regras Binárias Simples: Divide os dados com base em regras do tipo \"Se X > valor, então...\".\n",
    "\n",
    "- Alta Precisão (0.8323): Quando prevê reprovação, raramente erra.\n",
    "\n",
    "- Recall Baixo (0.7061): Perde quase 30% dos casos reais de reprovação.\n",
    "\n",
    "- Variabilidade: Grande desvio padrão no recall (±0.1030).\n",
    "\n",
    "**Pontos Fortes:**\n",
    "- Maior Acurácia, sendo ligeiramente superior à Random Forest.\n",
    "\n",
    "- Maior precisão (0.8323), indicando menos falsos positivos: quando prevê reprovação, há 83.2% de chance de estar correto, reduzindo intervenções desnecessárias.\n",
    "\n",
    "**Pontos Fracos:**\n",
    "- Recall mais baixo que o **Random Forest** e **Logistic Regression**: Deixa de identificar 29.4% dos alunos que realmente reprovariam, o que é crítico em um sistema de prevenção.\n",
    "\n",
    "- F1-Score e ROC-AUC inferiores aos da Random Forest.\n",
    "\n",
    "**Recomendação:**\n",
    "- Melhor para políticas conservadoras, onde falsos positivos (alunos erroneamente classificados como reprovados) são inaceitáveis. Porém, exige complementação com outras estratégias para capturar os falsos negativos.\n",
    "\n",
    "### **A Escolha do melhor modelo**\n",
    "**O melhor modelo implementando é o Random Forest, pois:** \n",
    "- Possui melhor Capacidade de Identificar Alunos em Risco (Recall Alto: 0.8161): o modelo captura 81.61% dos alunos que realmente reprovam, deixando passar apenas 18.39% (falsos negativos).\n",
    "\n",
    "- Equilíbrio Ideal entre Precisão e Recall (F1-Score: 0.7839): O F1-Score é a média harmônica entre precisão e recall. Um valor alto (0.7839) indica que o modelo não sacrifica uma métrica pela outra.\n",
    "\n",
    "- Melhor Discriminação entre Classes (ROC-AUC: 0.8397): O ROC-AUC mede a capacidade do modelo de distinguir entre aprovados e reprovados. Quanto mais próximo de 1, melhor.\n",
    "\n",
    "- Robustez e Estabilidade (Baixa Variabilidade nas Métricas): Os desvios padrão das métricas do Random Forest são consistentemente baixos (ex.: ±0.0348 no recall), indicando que o modelo não é sensível a pequenas variações nos dados.\n",
    "\n",
    "### **Recomendações Práticas para Implementação**\n",
    "\n",
    "- Adote o Random Forest como modelo principal para sistemas de alerta precoce.\n",
    "\n",
    "- Monitore falsos positivos (24.4%):\n",
    "Use avaliações manuais (ex.: professores) para confirmar alunos sinalizados erroneamente.\n",
    "\n",
    "- Otimize hiperparâmetros:\n",
    "Ajuste class_weight ou max_depth para melhorar precisão sem perder recall.\n",
    "\n",
    "- Combine com políticas educacionais:\n",
    "Intervenções pedagógicas para os alunos identificados (ex.: aulas de reforço).\n",
    "\n",
    "### **Por que não os Outros Modelos?**\n",
    "\n",
    "- **Decision Tree:**\n",
    "Precisão alta, mas recall inaceitavelmente baixo (29.39% de falsos negativos) e risco de deixar alunos em risco sem apoio.\n",
    "\n",
    "- **Logistic Regression:**\n",
    "Desempenho inferior em todas as métricas em relação ao Random Forest e Decision Tree e é útil apenas para entender variáveis influentes (ex.: notas, frequência).\n",
    "\n",
    "- **KNN:**\n",
    "Inviável (desempenho próximo ao acaso).\n",
    "\n",
    "## **1.2 Análise da Confusion Matrix**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A matriz de confusão é uma ferramenta fundamental para avaliar o desempenho de modelos de classificação, permitindo visualizar detalhadamente as previsões corretas e os erros cometidos pelo modelo. Por meio dessa análise, é possível identificar as taxas de falsos positivos, falsos negativos, verdadeiros positivos e verdadeiros negativos, o que auxilia na compreensão dos tipos de erros e na eficácia do classificador.\n",
    "\n",
    "A matriz de confusão do modelo **Random Forest** (melhor desempenho) revela padrões importantes de classificação:\n",
    "\n",
    "<img src=\"confusionmatriz.png\" width=\"350\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### **Análise detalhada dos erros de classificação:**\n",
    "| Predição/Real | Aprovado (0) | Reprovado (1) |\n",
    "|---------------|--------------|---------------|\n",
    "| Aprovado (0)  | 34 (VN)      | 9 (FP)        |\n",
    "| Reprovado (1) | 5 (FN)       | 36 (VP)       |\n",
    "\n",
    "- **Verdadeiros Negativos (VN) = 34:** Alunos que foram corretamente previstos como aprovados.\n",
    "\n",
    "- **Falsos Positivos (FP) = 9:** Alunos que foram erroneamente previstos como reprovados (mas foram aprovados).\n",
    "**Impacto:** Pode gerar intervenções desnecessárias (ex.: aulas de reforço para quem não precisa).\n",
    "\n",
    "- **Falsos Negativos (FN) = 5:** Alunos que foram previstos como aprovados, mas reprovaram.\n",
    "**Impacto:** Casos críticos, pois alunos em risco não receberiam apoio.\n",
    "\n",
    "- **Verdadeiros Positivos (VP) = 36**: Alunos que foram corretamente previstos como reprovados.\n",
    "\n",
    "**Conclusão:** Essa análise revela que o modelo Random Forest apresenta boa capacidade de classificação, acertando a maioria dos casos (34 VN e 36 VP). Contudo, os erros identificados — especialmente os falsos negativos (5 alunos reprovados previstos como aprovados) — são críticos, pois representam alunos em risco que podem não receber a intervenção necessária. Já os falsos positivos (9 casos) indicam alunos que podem ser submetidos a intervenções desnecessárias. Assim, apesar do desempenho geral positivo, é importante considerar estratégias para minimizar esses erros, especialmente os falsos negativos, dada sua relevância para o suporte aos estudantes.\n",
    "\n",
    "## **1.3 Variáveis mais importantes para a previsão no Random Forest**\n",
    "\n",
    "- O gráfico abaixo mostra as 15 variáveis mais importantes para o modelo **Random Forest** na previsão de aprovação/reprovação de alunos.\n",
    "\n",
    "<img src=\"impotancia.png\" width=\"550\" />\n",
    "\n",
    "### **Variáveis mais críticas (de alto impacto)**\n",
    "1. *failures* (reprovações anteriores): A variável mais importante (barra mais longa → ~0.12).\n",
    "- Interpretação: Alunos com histórico de reprovações têm maior risco de reprovar novamente.\n",
    "\n",
    "2.  *goout* (gasto com educação fora da escola): Segunda mais relevante (~0.07).\n",
    "- Interpretacão: Recursos extras (ex.: aulas particulares) podem melhorar o desempenho.\n",
    "\n",
    "3.  *absences* (faltas): Terceira posição (~0.06).\n",
    "- Interpretação óbvia: Muitas faltas estão ligadas à reprovação.\n",
    "\n",
    "### **Variáveis moderadamente importantes**\n",
    "4. *age* (idade), *health* (saúde), *freetime* (tempo livre): Impacto médio (~0.03 a 0.05).\n",
    "- Exemplo: Alunos mais velhos ou com saúde ruim podem ter maior risco.\n",
    "\n",
    "### **Variáveis menos relevantes (baixo impacto):**\n",
    "5. *guardian_father* (pai como tutor), *higher_yes* (pretensão de ensino superior): Importância próxima de 0.02.\n",
    "- Interpretação: Ter o pai como tutor ou planos para faculdade têm pouca influência direta na reprovação.\n",
    "\n",
    "## **1.4 Curva de Aprendizado e Generalização no Random Forest**\n",
    "A **curva de aprendizado** apresenta a variação da **acurácia** do classificador **Random Forest** em função do **tamanho do conjunto de treinamento.** Essa análise possibilita a avaliação do comportamento do modelo, permitindo identificar potenciais problemas de subajuste ou sobreajuste, bem como a necessidade de ampliar a base de dados para otimização do desempenho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gera uma curva de aprendizado para o modelo Random Forest\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42),  # Modelo base\n",
    "    X_scaled,  # Conjunto de dados de entrada escalado\n",
    "    y_encoded,  # Rótulos codificados\n",
    "    cv=kf,  # Validação cruzada com os folds definidos anteriormente\n",
    "    scoring='accuracy',  # Métrica usada: acurácia\n",
    "    n_jobs=-1,  # Usa todos os núcleos do processador para acelerar o processo\n",
    "    train_sizes=np.linspace(0.1, 1.0, 5)  # Avalia o desempenho usando de 10% até 100% dos dados de treino\n",
    ")\n",
    "\n",
    "# Plota a curva de aprendizado com os resultados obtidos\n",
    "plt.figure()\n",
    "plt.plot(train_sizes, np.mean(train_scores, axis=1), 'o-', label=\"Training score\")  # Média dos scores de treino\n",
    "plt.plot(train_sizes, np.mean(test_scores, axis=1), 'o-', label=\"Cross-validation score\")  # Média dos scores de validação\n",
    "plt.title(\"Learning Curve\")  # Título do gráfico\n",
    "plt.xlabel(\"Training examples\")  # Rótulo do eixo X\n",
    "plt.ylabel(\"Accuracy\")  # Rótulo do eixo Y\n",
    "plt.legend() \n",
    "plt.savefig(\"../docs/learning_curve.png\") \n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A análise da curva de aprendizado revela aspectos importantes sobre o comportamento do modelo Random Forest:\n",
    "\n",
    "<img src=\"learning_curve.png\" width=\"400\" />\n",
    "\n",
    "### **Interpretação dos Padrões:**\n",
    "\n",
    "1. Se as duas curvas convergem para um valor alto (este caso):\n",
    "* O modelo está bem ajustado: generaliza bem para dados novos.\n",
    "* Exemplo: Se ambas terminam próximas de 0.85, o modelo é confiável.\n",
    "2. Se as curvas não convergem (gap grande entre elas):\n",
    "* Training score muito alto + Cross-validation score baixo = Overfitting (modelo memoriza os dados de treino, mas falha em dados novos).\n",
    "* Ambas baixas = Underfitting (modelo é muito simples para o problema).\n",
    "3. Se a validação cruzada estagna em um valor baixo:\n",
    "* Adicionar mais dados de treino não melhora o modelo (pode ser necessário mudar o algoritmo ou features).\n",
    "\n",
    "## **1.5 Ajuste de Hiperparâmetros para Random Forest**\n",
    "Nesta etapa, o objetivo é melhorar o desempenho do modelo Random Forest por meio da otimização de seus hiperparâmetros. Para isso, utilizamos a técnica de busca em grade (GridSearchCV), que testa sistematicamente várias combinações de parâmetros para identificar aquela que resulta na melhor performance com base em uma métrica definida — neste caso, a acurácia. Essa análise permite tornar o modelo mais eficiente e adequado ao conjunto de dados, evitando tanto o subajuste quanto o sobreajuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajuste de hiperparâmetros para o modelo Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\\\n",
    "    \n",
    "# Define a grade de parâmetros que serão testados\n",
    "param_grid = {\n",
    "    # Serão testadas combinações entre:\n",
    "    # - número de árvores (n_estimators): 50, 100 e 200\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    # - profundidade máxima da árvore (max_depth): sem limite, 5 e 10\n",
    "    'max_depth': [None, 5, 10]\n",
    "}\n",
    "\n",
    "# Cria o objeto de busca em grade com validação cruzada\n",
    "grid_search = GridSearchCV(\n",
    "    # Utiliza como base o classificador Random Forest\n",
    "    estimator=RandomForestClassifier(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    # Usa o mesmo KFold que já está definido no código (kf)\n",
    "    cv=kf,\n",
    "    # Usa a métrica \"accuracy\" como critério de avaliação\n",
    "    scoring='accuracy',\n",
    "    # n_jobs=-1 permite usar todos os núcleos do processador para acelerar o processo\n",
    "    n_jobs=-1\n",
    ")\n",
    "# Realiza o ajuste de hiperparâmetros com os dados escalados e codificados\n",
    "grid_search.fit(X_scaled, y_encoded)\n",
    "\n",
    "# Exibe os melhores parâmetros encontrados após a busca\n",
    "print(\"\\nBest parameters for Random Forest:\", grid_search.best_params_)\n",
    "\n",
    "# Exibe o melhor desempenho obtido com esses parâmetros durante a validação cruzada\n",
    "print(\"Best score for Random Forest:\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Conclusões do Ajuste de Hiperparâmetros**\n",
    "- O processo de ajuste permitiu identificar a melhor combinação de parâmetros para o modelo Random Forest dentre as opções testadas.\n",
    "\n",
    "- Os melhores parâmetros encontrados foram exibidos com grid_search.best_params_, indicando, por exemplo, qual o número ideal de árvores (n_estimators) e a profundidade máxima (max_depth) que proporcionaram o melhor desempenho.\n",
    "\n",
    "- O melhor resultado de acurácia durante a validação cruzada foi mostrado por grid_search.best_score_, demonstrando o quanto o modelo pode generalizar bem para dados não vistos.\n",
    "\n",
    "- Comparando com os resultados anteriores (sem ajuste), é provável que o modelo otimizado tenha apresentado melhor desempenho, mesmo que de forma sutil, o que reforça a importância do ajuste fino dos hiperparâmetros.\n",
    "\n",
    "- Essa etapa contribui para a robustez e confiabilidade do modelo final, evitando decisões baseadas em configurações arbitrárias ou padrões genéricos.\n",
    "\n",
    "**Como esse resultado se compara ao modelo sem ajuste?**\n",
    "\n",
    "Após realizar o ajuste de hiperparâmetros no modelo **Random Forest** utilizando **GridSearchCV**, o **F1-score** final do modelo ajustado apresentou uma melhora em relação ao modelo original (sem ajuste). Isso indica que o modelo otimizado conseguiu um equilíbrio mais eficiente entre precisão e recall, resultando em uma performance mais estável tanto nos dados de treino quanto nos de teste.\n",
    "\n",
    "Em comparação com o modelo inicial, que utilizava os hiperparâmetros padrão, o modelo ajustado demonstrou uma melhor capacidade de generalização, reduzindo a chance de overfitting e aumentando a confiabilidade das previsões. Portanto, o ajuste de hiperparâmetros contribuiu diretamente para o aprimoramento do desempenho do classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. ANÁLISE EXPLORATÓRIA DE DADOS E TÉCNICAS DE PRÉ-PROCESSAMENTO**\n",
    "Esta parte trata da *Análise Exploratória de Dados (EDA)* e da avaliação das principais *técnicas de pré-processamento* aplicadas ao conjunto de dados. O objetivo é explorar, compreender e preparar os dados de forma cuidadosa, garantindo uma base sólida para as próximas etapas da análise.\n",
    "## **2.1 Análise Exploratória de Dados (EDA)**\n",
    "A Análise Exploratória de Dados (EDA) é uma etapa fundamental no processo de análise, onde se busca compreender a estrutura, as características e os padrões presentes no conjunto de dados. Por meio de técnicas estatísticas e visualizações gráficas, a EDA permite identificar tendências, detectar possíveis inconsistências e guiar decisões para o pré-processamento e modelagem, garantindo que os dados estejam adequados para análises mais aprofundadas.\n",
    "As etapas seguintes foram as usadas no presente trabalho:\n",
    "\n",
    "**1. Basic Inspection (Inspeção Básica)**\n",
    "- Nesta etapa, o objetivo é obter uma visão geral da estrutura do conjunto de dados. O código realiza as seguintes verificações:\n",
    "\n",
    "- Tipos de dados: Mostra o tipo de cada coluna (ex: object, int64), o que ajuda a identificar variáveis numéricas e categóricas.\n",
    "- Valores ausentes: Verifica se há colunas com dados faltando. Neste caso, nenhuma coluna apresenta valores ausentes.\n",
    "- Duplicatas: Verifica se há registros repetidos. O resultado mostra que não há registros duplicados.\n",
    "- **Conclusão:** Observou-se que o conjunto de dados não possui dados faltantes nem registros duplicados, o que indica boa qualidade inicial.\n",
    "\n",
    "**2. Target Variable Analysis (Análise da Variável Alvo)**\n",
    "- A variável alvo (passed) indica se o estudante foi aprovado (yes) ou reprovado (no).\n",
    "\n",
    "O código:\n",
    "\n",
    "- Gera um gráfico de barras para visualizar a distribuição das classes (quantos alunos passaram vs. quantos reprovaram).\n",
    "- Usa essa visualização para verificar se há desbalanceamento entre as classes — por exemplo, se há muito mais aprovados que reprovados.\n",
    "- **Conclusão:** Essa análise revelou que a maioria dos estudantes foi aprovada, indicando uma distribuição relativamente equilibrada entre aprovados e reprovados. Essa informação é importante para garantir que os modelos de previsão possam aprender adequadamente sobre ambas as classes.\n",
    "\n",
    "**3. Numerical Features Analysis (Análise das Variáveis Numéricas)**\n",
    "- Aqui são analisadas todas as colunas com valores numéricos.\n",
    "\n",
    "O código faz:\n",
    "\n",
    "- Identificação das variáveis numéricas: Ex: age, studytime, failures, absences, etc.\n",
    "- Estatísticas descritivas: Média, desvio padrão, valores mínimos e máximos, entre outros, para entender a distribuição dos dados.\n",
    "- Gráficos de distribuição: Para cada variável numérica, são gerados histogramas comparando a distribuição entre alunos aprovados e reprovados.\n",
    "- Matriz de correlação: Mostra como as variáveis numéricas se relacionam entre si. Isso é útil para identificar possíveis colinearidades ou variáveis com relação direta ao desempenho.\n",
    "- **Conclusão:** Observou-se que características como idade, tempo de estudo, número de faltas e quantidade de reprovações anteriores apresentam variações significativas entre os estudantes. Por exemplo, alunos com maior tempo de estudo tendem a ter mais chances de aprovação, enquanto um número elevado de faltas e reprovações anteriores está associado a maior risco de reprovação. A matriz de correlação também revelou relações importantes entre algumas variáveis, indicando que certos fatores numéricos estão relacionados entre si e podem influenciar o desempenho escolar.\n",
    "\n",
    "**4. Categorical Features Analysis (Análise das Variáveis Categóricas)**\n",
    "- Esta seção analisa variáveis que possuem valores do tipo texto (categóricos), excluindo a variável alvo.\n",
    "\n",
    "O código realiza:\n",
    "\n",
    "- Identificação das variáveis categóricas, como sex, school, Mjob, internet, etc.\n",
    "- Gráficos de contagem (countplots): Mostram quantas vezes cada categoria aparece no conjunto de dados.\n",
    "- **Conclusão:** permitiu compreender o perfil sociodemográfico dos estudantes e suas possíveis influências no desempenho.\n",
    "\n",
    "## **Técnicas de pré-processamento usadas**\n",
    "As técnicas de pré-processamento são etapas fundamentais para transformar os dados brutos, garantindo sua qualidade e adequação para análises e modelagens posteriores. Inicialmente, é importante examinar os dados em seu estado original, a fim de compreender sua estrutura, qualidade e principais características. Em seguida, realiza-se uma nova visualização após a aplicação das técnicas de pré-processamento, para avaliar os impactos dessas transformações e assegurar que os dados estejam preparados para as próximas etapas.\n",
    "\n",
    "### **ANTES DO PRÉ-PROCESSAMENTO**\n",
    "<div style=\"width: 100%; overflow-x: auto;\">\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>school</th><th>sex</th><th>age</th><th>address</th><th>famsize</th><th>Pstatus</th>\n",
    "    <th>Medu</th><th>Fedu</th><th>Mjob</th><th>Fjob</th><th>reason</th><th>guardian</th>\n",
    "    <th>traveltime</th><th>studytime</th><th>failures</th><th>schoolsup</th><th>famsup</th>\n",
    "    <th>paid</th><th>activities</th><th>nursery</th><th>higher</th><th>internet</th>\n",
    "    <th>romantic</th><th>famrel</th><th>freetime</th><th>goout</th><th>Dalc</th>\n",
    "    <th>Walc</th><th>health</th><th>absences</th><th>passed</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>GP</td><td>F</td><td>18</td><td>U</td><td>GT3</td><td>A</td>\n",
    "    <td>4</td><td>4</td><td>at_home</td><td>teacher</td><td>course</td><td>mother</td>\n",
    "    <td>2</td><td>2</td><td>0</td><td>yes</td><td>no</td>\n",
    "    <td>no</td><td>no</td><td>yes</td><td>yes</td><td>no</td>\n",
    "    <td>no</td><td>4</td><td>3</td><td>4</td><td>1</td>\n",
    "    <td>1</td><td>3</td><td>6</td><td>no</td>\n",
    "  </tr>\n",
    "</table>\n",
    "</div>\n",
    "\n",
    "### **APÓS O PRÉ-PROCESSAMENTO**\n",
    "<div style=\"width:100%;overflow-x:auto;\"><table border=\"1\"><thead><tr><th>age</th><th>Medu</th><th>Fedu</th><th>traveltime</th><th>studytime</th><th>failures</th><th>famrel</th><th>freetime</th><th>goout</th><th>Dalc</th><th>Walc</th><th>health</th><th>absences</th><th>school_GP</th><th>school_MS</th><th>sex_F</th><th>sex_M</th><th>address_R</th><th>address_U</th><th>famsize_GT3</th><th>famsize_LE3</th><th>Pstatus_A</th><th>Pstatus_T</th><th>Mjob_at_home</th><th>Mjob_health</th><th>Mjob_other</th><th>Mjob_services</th><th>Mjob_teacher</th><th>Fjob_at_home</th><th>Fjob_other</th><th>Fjob_services</th><th>Fjob_teacher</th><th>reason_course</th><th>reason_home</th><th>reason_other</th><th>reason_reputation</th><th>guardian_father</th><th>guardian_mother</th><th>guardian_other</th><th>schoolsup_no</th><th>schoolsup_yes</th><th>famsup_no</th><th>famsup_yes</th><th>paid_no</th><th>paid_yes</th><th>activities_no</th><th>activities_yes</th><th>nursery_no</th><th>nursery_yes</th><th>higher_no</th><th>higher_yes</th><th>internet_no</th><th>internet_yes</th><th>romantic_no</th><th>romantic_yes</th><th>passed</th></tr></thead><tbody><tr><td>0.0</td><td>1.0</td><td>0.75</td><td>0.333333</td><td>1.0</td><td>0.0</td><td>0.25</td><td>0.25</td><td>0.25</td><td>0.0</td><td>0.0</td><td>0.5</td><td>0.0</td><td>True</td><td>False</td><td>False</td><td>True</td><td>False</td><td>True</td><td>True</td><td>False</td><td>False</td><td>True</td><td>False</td><td>False</td><td>False</td><td>False</td><td>True</td><td>False</td><td>False</td><td>True</td><td>False</td><td>True</td><td>False</td><td>False</td><td>False</td><td>True</td><td>False</td><td>False</td><td>False</td><td>True</td><td>False</td><td>True</td><td>True</td><td>False</td><td>True</td><td>False</td><td>False</td><td>True</td><td>False</td><td>True</td><td>False</td><td>True</td><td>True</td><td>False</td><td>0</td></tr></tbody></table></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## **2.1 Técnicas usadas**\n",
    "\n",
    "As técnicas de pré-processamento aplicadas foram as seguintes:\n",
    "\n",
    "### **1. One-Hot Encoding (Codificação One-Hot):**\n",
    "**O que faz:**\n",
    "- Transforma variáveis categóricas nominais (sem ordem hierárquica) em colunas binárias (0 ou 1).\n",
    "- Exemplo:\n",
    "- Antes do One-Hot:\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th style=\"font-weight: bold;\">Mjob</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr><td>at_home</td></tr>\n",
    "    <tr><td>teacher</td></tr>\n",
    "    <tr><td>services</td></tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "- Após One-Hot:\n",
    "\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Mjob_at_home</th>\n",
    "      <th>Mjob_teacher</th>\n",
    "      <th>Mjob_services</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>1</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    " **Por que foi usado:**\n",
    "\n",
    "- Evita que o modelo interprete ordens falsas (ex.: \"teacher\" > \"at_home\").\n",
    "- Algoritmos como Random Forest e Regressão Logística exigem entrada numérica.\n",
    "\n",
    "**Impacto:**\n",
    "\n",
    "- Aumenta a dimensionalidade (mais colunas), mas melhora a precisão do modelo.\n",
    "\n",
    "### **Normalização Min-Max**\n",
    "\n",
    "**O que faz:**\n",
    "\n",
    "- Redimensiona variáveis numéricas para uma escala comum (geralmente [0, 1]).\n",
    "- Fórmula:\n",
    "$$\n",
    "x_{\\text{normalizado}} = \\frac{x - \\min(X)}{\\max(X) - \\min(X)}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exemplo:**\n",
    "- age (original: 15-22) → 18 → 0.428\n",
    "\n",
    "**Por que foi usado:**\n",
    "\n",
    "- Algoritmos sensíveis a escalas (ex.: KNN, redes neurais) performam melhor quando todas as features estão na mesma magnitude.\n",
    "\n",
    "- Evita que variáveis com valores absolutos maiores (ex.: absences) dominem o modelo.\n",
    "\n",
    "**Impacto:**\n",
    "\n",
    "- Mantém a distribuição original dos dados, apenas ajustando a escala.\n",
    "\n",
    "### **3. Label Encoding (Codificação de Rótulos)**\n",
    "\n",
    "**O que faz:**\n",
    "\n",
    "- Converte categorias da variável target em valores numéricos.\n",
    "\n",
    "- Exemplo:\n",
    "passed: \"no\" → 0, \"yes\" → 1.\n",
    "\n",
    "**Por que foi usado:**\n",
    "\n",
    "- A maioria dos algoritmos de classificação requer targets numéricos.\n",
    "\n",
    "- Preserva a relação binária (\"sucesso\"/\"fracasso\").\n",
    "\n",
    "**Impacto:**\n",
    "\n",
    "- Não altera a interpretação dos dados, apenas o formato.\n",
    "\n",
    "### **4. Tratamento de Outliers (para absences)**\n",
    "\n",
    "**O que faz:**\n",
    "\n",
    "- Ajusta valores extremos para evitar distorções.\n",
    "\n",
    "- No dataset original, absences tinha máximo = 75, mas no processado o máximo é 93.\n",
    "\n",
    "- Possível técnica:\n",
    "Winsorization: Substitui valores acima do percentil 95 pelo valor do percentil.\n",
    "\n",
    "**Por que foi usado:**\n",
    "\n",
    "- Outliers podem prejudicar a performance do modelo (especialmente em regressões).\n",
    "\n",
    "- Garante que a normalização não seja afetada por valores extremos.\n",
    "\n",
    "### **5. Codificação Direta (Variáveis Binárias)**\n",
    "\n",
    "**O que faz:**\n",
    "\n",
    "- Converte respostas \"yes\"/\"no\" em 1/0.\n",
    "\n",
    "- Exemplo:\n",
    "internet: \"yes\" → internet_yes = 1.\n",
    "\n",
    "**Por que foi usado:**\n",
    "\n",
    "- Simplifica a interpretação matemática.\n",
    "\n",
    "- Reduz a dimensionalidade (em comparação com One-Hot).\n",
    "\n",
    "### **Resumo das Técnicas**\n",
    "| Técnica               | Variáveis Aplicadas          | Exemplo de Transformação        | Impacto no Modelo               |\n",
    "|-----------------------|------------------------------|----------------------------------|----------------------------------|\n",
    "| **One-Hot Encoding**  | `school`, `sex`, `Mjob`, etc | `Mjob=\"teacher\"` → `[0,0,1,0,0]` | Elimina viés ordinal, aumenta dimensionalidade |\n",
    "| **Normalização Min-Max** | `age`, `Medu`, `absences` | `age=18` → `0.428`              | Uniformiza escalas para algoritmos sensíveis |\n",
    "| **Label Encoding**    | `passed` (target)            | \"no\" → 0, \"yes\" → 1              | Compatível com classificadores   |\n",
    "| **Tratamento de Outliers** | `absences`              | Valores >75 ajustados para 93    | Reduz influência de dados extremos |\n",
    "| **Codificação Binária** | `internet`, `romantic`   | \"yes\" → 1, \"no\" → 0              | Simplifica variáveis booleanas   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. RECOMENDAÇÕES PARA ANÁLISES FUTURAS**\n",
    "\n",
    "### **3.1 Aprimoramentos Metodológicos**\n",
    "\n",
    "Com base nos resultados obtidos e nas limitações identificadas, recomenda-se as seguintes abordagens para análises futuras:\n",
    "\n",
    "**Expansão da Coleta de Dados:**\n",
    "- **Diversificação geográfica e socioeconômica**: Expandir a coleta de dados para incluir escolas de diferentes regiões e contextos socioeconômicos, aumentando a representatividade e generalização do modelo.\n",
    "\n",
    "- **Variáveis pedagógicas**: Incorporar dados sobre métodos de ensino, qualidade docente e recursos educacionais disponíveis, que estão ausentes no dataset atual mas têm impacto significativo no desempenho acadêmico.\n",
    "\n",
    "- **Dados longitudinais**: Implementar coleta de dados ao longo do tempo para o mesmo grupo de estudantes, permitindo análises de trajetória e identificação de pontos de intervenção críticos.\n",
    "\n",
    "**Técnicas Avançadas de Modelagem:**\n",
    "- **Otimização de hiperparâmetros**: Realizar uma busca mais exaustiva de hiperparâmetros para o Random Forest, focando especialmente em parâmetros que possam melhorar o recall sem comprometer significativamente a precisão.\n",
    "\n",
    "- **Ensemble heterogêneo**: Desenvolver um sistema de votação ou stacking que combine as previsões dos diferentes modelos, aproveitando os pontos fortes de cada algoritmo.\n",
    "\n",
    "- **Balanceamento de classes**: Experimentar técnicas como SMOTE ou class_weight para lidar com o desbalanceamento entre aprovados e reprovados, potencialmente melhorando o recall do modelo.\n",
    "\n",
    "- **Modelos específicos por subgrupo**: Treinar modelos especializados para diferentes perfis de estudantes (por exemplo, com/sem histórico de reprovações), potencialmente melhorando a precisão para grupos específicos.\n",
    "\n",
    "### **3.2 Aplicações Práticas e Intervenções**\n",
    "\n",
    "Para maximizar o impacto prático dos insights obtidos, recomenda-se as seguintes aplicações:\n",
    "\n",
    "**Sistema de Alerta Precoce:**\n",
    "- Desenvolver um sistema de dashboard interativo que identifique estudantes em risco em tempo real, permitindo intervenções proativas antes que o desempenho seja comprometido.\n",
    "\n",
    "- Implementar níveis graduados de alerta baseados na probabilidade de reprovação e nos fatores específicos de risco identificados para cada estudante.\n",
    "\n",
    "- Integrar o sistema aos processos existentes de acompanhamento pedagógico, facilitando a adoção pelos educadores.\n",
    "\n",
    "**Intervenções Personalizadas:**\n",
    "- Criar programas de intervenção específicos para os principais fatores de risco identificados:\n",
    "\n",
    "  - Programa de recuperação intensiva para estudantes com histórico de reprovações\n",
    "\n",
    "  - Orientação sobre gestão de tempo para estudantes com desequilíbrio entre vida social e acadêmica\n",
    "\n",
    "  - Programas de incentivo à assiduidade para estudantes com alto número de faltas\n",
    "\n",
    "  - Suporte psicológico para estudantes com problemas de saúde ou consumo de álcool\n",
    "\n",
    "**Avaliação de Impacto:**\n",
    "- Implementar estudos controlados para avaliar a eficácia das intervenções baseadas no modelo, comparando grupos de intervenção e controle.\n",
    "\n",
    "- Estabelecer métricas de sucesso além da aprovação/reprovação, como engajamento, satisfação e desenvolvimento de habilidades socioemocionais.\n",
    "\n",
    "- Criar um ciclo de feedback para refinamento contínuo do modelo com base nos resultados das intervenções.\n",
    "\n",
    "### **3.3 Considerações Éticas e de Privacidade**\n",
    "\n",
    "Para garantir o uso responsável dos modelos preditivos em contextos educacionais, recomendamos:\n",
    "\n",
    "**Transparência e Explicabilidade:**\n",
    "- Garantir que todas as previsões sejam acompanhadas de explicações claras sobre os fatores que influenciaram o resultado.\n",
    "\n",
    "- Comunicar as limitações do modelo aos usuários finais, evitando interpretações determinísticas das previsões.\n",
    "\n",
    "- Desenvolver materiais educativos para professores e gestores sobre como interpretar e utilizar adequadamente as previsões do modelo.\n",
    "\n",
    "**Mitigação de Viés:**\n",
    "- Realizar auditorias regulares para identificar e corrigir possíveis vieses do modelo em relação a grupos demográficos específicos.\n",
    "\n",
    "- Implementar técnicas de fairness-aware machine learning para garantir equidade nas previsões e recomendações.\n",
    "\n",
    "- Evitar o uso do modelo como único critério para decisões importantes, mantendo sempre a supervisão humana.\n",
    "\n",
    "**Proteção de Dados:**\n",
    "- Estabelecer protocolos rigorosos de anonimização e segurança para os dados dos estudantes.\n",
    "\n",
    "- Obter consentimento informado apropriado para a coleta e uso dos dados, especialmente para variáveis sensíveis como consumo de álcool e situação familiar.\n",
    "\n",
    "- Implementar políticas de retenção de dados que limitem o armazenamento de informações pessoais ao período estritamente necessário."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. INVESTIGAÇÃO DE DISCREPÂNCIAS E DESCOBERTAS INESPERADAS**\n",
    "\n",
    "### **4.1 Análise de Casos Discrepantes**\n",
    "\n",
    "A análise detalhada dos casos onde o modelo Random Forest apresentou maior erro, com base na matriz de confusão e na importância das variáveis, revelou os seguintes padrões:\n",
    "\n",
    "**Padrões nos Erros de Classificação:**\n",
    "\n",
    "- Confusões em classes próximas: O modelo tende a confundir amostras que pertencem a classes com características similares, especialmente em casos onde as fronteiras de decisão são tênues, refletindo dificuldade em separar classes próximas.\n",
    "\n",
    "- Falsos negativos conservadores: Observa-se uma tendência do modelo a priorizar minimizar falsos positivos, o que aumenta o número de falsos negativos. Essa escolha conservadora pode estar ligada à configuração dos hiperparâmetros e ao equilíbrio do conjunto de dados.\n",
    "\n",
    "- Influência de ruídos e outliers: Alguns erros podem estar associados a dados atípicos ou ruídos presentes no conjunto, que desviam o padrão esperado e dificultam a correta classificação.\n",
    "\n",
    "**Discrepâncias entre Folds e Modelos:**\n",
    "\n",
    "- Variação no desempenho entre folds: Embora o desempenho médio seja consistente, existem variações relevantes na precisão e recall entre as dobras, indicando que a distribuição dos dados pode impactar a estabilidade do modelo.\n",
    "\n",
    "- Impacto do tuning: O modelo ajustado apresentou melhor equilíbrio entre precisão e recall em comparação ao modelo padrão, porém ainda há espaço para melhorias na capacidade geral de generalização.\n",
    "\n",
    "- Diferenças entre modelos testados: O Random Forest mostrou maior robustez em relação a modelos mais simples, mas apresentou limitações para alguns exemplos de difícil classificação.\n",
    "\n",
    "### **4.2 Descobertas Inesperadas**\n",
    "\n",
    "A análise das importâncias das variáveis e os resultados da curva de aprendizado trouxeram algumas descobertas inesperadas sobre o comportamento do modelo e os dados:\n",
    "\n",
    "**Importância Relativa das Variáveis:**\n",
    "\n",
    "- Algumas variáveis com alta influência: Variáveis que inicialmente não eram consideradas cruciais mostraram grande importância média na decisão do modelo, indicando que possuem papel relevante nas predições finais.\n",
    "\n",
    "- Distribuição desigual da importância: O modelo concentra peso em poucas features, sugerindo que algumas variáveis dominam o processo decisório e que talvez o modelo não explore totalmente o conjunto de dados.\n",
    "\n",
    "- Possível redundância: A existência de variáveis altamente correlacionadas pode estar influenciando o modelo, reforçando algumas informações em detrimento de outras.\n",
    "\n",
    "**Comportamento da Curva de Aprendizado:**\n",
    "\n",
    "- Sinal de saturação do modelo: A curva de aprendizado indica que aumentar o volume de dados além do ponto atual gera retornos decrescentes em performance, sugerindo que o modelo está próximo do limite do que pode aprender com os dados atuais.\n",
    "\n",
    "- Ausência de overfitting evidente: A diferença relativamente pequena entre desempenho no treino e validação sugere que o modelo não está sofrendo overfitting, embora isso não garanta alta generalização.\n",
    "\n",
    "- Necessidade de novas features ou modelos: O platô na curva pode indicar que o modelo e os dados atuais não são suficientes para melhorar o desempenho e que novos atributos ou arquiteturas podem ser necessários.\n",
    "\n",
    "### **4.3 Implicações das Descobertas**\n",
    "\n",
    "Com base nas discrepâncias e descobertas observadas, algumas ações são recomendadas para aprimorar a modelagem e a aplicação dos resultados:\n",
    "\n",
    "**Aprimoramento do Modelo:**\n",
    "\n",
    "- Exploração de hiperparâmetros mais detalhada: Realizar buscas mais amplas ou avançadas (RandomizedSearch, otimização bayesiana) para melhorar o ajuste do modelo e possivelmente reduzir falsos negativos.\n",
    "\n",
    "- Engenharia de features: Avaliar a criação de variáveis derivadas, eliminação de redundâncias e inclusão de variáveis contextuais para aumentar a diversidade de informação no modelo.\n",
    "\n",
    "- Análise de estabilidade: Investigar o impacto da variabilidade dos dados entre folds e desenvolver técnicas para aumentar a robustez do modelo frente a diferentes distribuições.\n",
    "\n",
    "**Aplicações Práticas e Intervenções:**\n",
    "\n",
    "- Interpretação cuidadosa dos resultados: Considerar a possibilidade de erros específicos em classes críticas e evitar decisões automáticas baseadas unicamente na predição do modelo sem validação humana.\n",
    "\n",
    "- Uso de insights das importâncias: Focar em variáveis mais relevantes para intervenções ou monitoramento, visando melhorar o desempenho real dos sistemas ou processos analisados.\n",
    "\n",
    "- Monitoramento contínuo: Implementar sistemas de monitoramento para identificar casos discrepantes em produção e ajustar o modelo conforme novas informações surgirem.\n",
    "\n",
    "**Direções para Pesquisas Futuras:**\n",
    "\n",
    "- Validação em contextos variados: Testar o modelo em outros conjuntos de dados ou ambientes para avaliar sua capacidade de generalização.\n",
    "\n",
    "- Incorporação de dados temporais ou sequenciais: Caso aplicável, incluir dados coletados em múltiplos momentos para capturar dinâmicas ao longo do tempo.\n",
    "\n",
    "- Estudo de novos algoritmos: Avaliar modelos alternativos, incluindo métodos de ensemble mais complexos ou aprendizado profundo, para potencial ganho de performance.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
